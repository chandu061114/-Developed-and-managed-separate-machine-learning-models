{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0b0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_additional_features(data):\n",
    "    data['daily_returns'] = data['Close'].pct_change()*100\n",
    "    # Relative Strength Index (RSI)\n",
    "    period = 14\n",
    "    data['rsi'] = 100 - (100 / (1 + data['daily_returns'].rolling(window=period, min_periods=1).apply(lambda x: x[x > 0].mean(), raw=True) /\n",
    "                                  data['daily_returns'].rolling(window=period, min_periods=1).apply(lambda x: x[x < 0].mean(), raw=True)))\n",
    "\n",
    "    # Bollinger Bands\n",
    "    window = 20\n",
    "    data['ma'] = data['Close'].rolling(window=window).mean()\n",
    "    data['std'] = data['Close'].rolling(window=window).std()\n",
    "    data['upper_band'] = data['ma'] + (2 * data['std'])\n",
    "    data['lower_band'] = data['ma'] - (2 * data['std'])\n",
    "\n",
    "    # Moving Averages (5, 20, 50, 100)\n",
    "    data['ma_5'] = data['Close'].rolling(window=5).mean()\n",
    "    data['ma_20'] = data['Close'].rolling(window=20).mean()\n",
    "    data['ma_50'] = data['Close'].rolling(window=50).mean()\n",
    "    data['ma_100'] = data['Close'].rolling(window=100).mean()\n",
    "\n",
    "    # Two Volume-based Indicators\n",
    "    data['volume_ma_5'] = data['Volume'].rolling(window=5).mean()\n",
    "    data['volume_ma_20'] = data['Volume'].rolling(window=20).mean()\n",
    "\n",
    "    # Percentage Change for Last 1, 3, 5 Days\n",
    "    data['pct_change_1d'] = data['Close'].pct_change(1)\n",
    "    data['pct_change_3d'] = data['Close'].pct_change(3)\n",
    "    data['pct_change_5d'] = data['Close'].pct_change(5)\n",
    "\n",
    "    # High and Low Prices for Last 1, 3, 5, 8, 13, 21 Days\n",
    "    periods = [1, 3, 5, 8, 13, 21]\n",
    "    for period in periods:\n",
    "        data[f'high_{period}d'] = data['High'].rolling(window=period).max()\n",
    "        data[f'low_{period}d'] = data['Low'].rolling(window=period).min()\n",
    "\n",
    "    # Peaks and Troughs\n",
    "    data['peak'] = (data['Close'] > data['Close'].shift(1)) & (data['Close'] > data['Close'].shift(-1))\n",
    "    data['trough'] = (data['Close'] < data['Close'].shift(1)) & (data['Close'] < data['Close'].shift(-1))\n",
    "\n",
    "    return data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706e9277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarning and FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Your existing code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f032f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_features(data):\n",
    "    # ... (previous code)\n",
    "\n",
    "    # Extract additional time-based features\n",
    "    data['day'] = data.index.day\n",
    "    data['month'] = data.index.month\n",
    "    data['week'] = data.index.isocalendar().week  # Corrected line\n",
    "    data['year'] = data.index.year\n",
    "    data['quarter'] = data.index.quarter\n",
    "    data['weekday'] = data.index.dayofweek  # Day of the week (0 = Monday, 6 = Sunday)\n",
    "\n",
    "\n",
    "    return data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfdd672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_head_shoulder(df, window=3):\n",
    "# Define the rolling window\n",
    "    roll_window = window\n",
    "    # Create a rolling window for High and Low\n",
    "    df['high_roll_max'] = df['High'].rolling(window=roll_window).max()\n",
    "    df['low_roll_min'] = df['Low'].rolling(window=roll_window).min()\n",
    "    # Create a boolean mask for Head and Shoulder pattern\n",
    "    mask_head_shoulder = ((df['high_roll_max'] > df['High'].shift(1)) & (df['high_roll_max'] > df['High'].shift(-1)) & (df['High'] < df['High'].shift(1)) & (df['High'] < df['High'].shift(-1)))\n",
    "    # Create a boolean mask for Inverse Head and Shoulder pattern\n",
    "    mask_inv_head_shoulder = ((df['low_roll_min'] < df['Low'].shift(1)) & (df['low_roll_min'] < df['Low'].shift(-1)) & (df['Low'] > df['Low'].shift(1)) & (df['Low'] > df['Low'].shift(-1)))\n",
    "    # Create a new column for Head and Shoulder and its inverse pattern and populate it using the boolean masks\n",
    "    df['head_shoulder_pattern'] = np.nan\n",
    "    df.loc[mask_head_shoulder, 'head_shoulder_pattern'] = 1\n",
    "    df.loc[mask_inv_head_shoulder, 'head_shoulder_pattern'] = 2\n",
    "    return df \n",
    "    # return not df['head_shoulder_pattern'].isna().any().item()\n",
    "\n",
    "def detect_multiple_tops_bottoms(df, window=3):\n",
    "# Define the rolling window\n",
    "    roll_window = window\n",
    "    # Create a rolling window for High and Low\n",
    "    df['high_roll_max'] = df['High'].rolling(window=roll_window).max()\n",
    "    df['low_roll_min'] = df['Low'].rolling(window=roll_window).min()\n",
    "    df['close_roll_max'] = df['Close'].rolling(window=roll_window).max()\n",
    "    df['close_roll_min'] = df['Close'].rolling(window=roll_window).min()\n",
    "    # Create a boolean mask for multiple top pattern\n",
    "    mask_top = (df['high_roll_max'] >= df['High'].shift(1)) & (df['close_roll_max'] < df['Close'].shift(1))\n",
    "    # Create a boolean mask for multiple bottom pattern\n",
    "    mask_bottom = (df['low_roll_min'] <= df['Low'].shift(1)) & (df['close_roll_min'] > df['Close'].shift(1))\n",
    "    # Create a new column for multiple top bottom pattern and populate it using the boolean masks\n",
    "    df['multiple_top_bottom_pattern'] = np.nan\n",
    "    df.loc[mask_top, 'multiple_top_bottom_pattern'] = 1\n",
    "    df.loc[mask_bottom, 'multiple_top_bottom_pattern'] = 2\n",
    "    return df\n",
    "\n",
    "def calculate_support_resistance(df, window=3):\n",
    "# Define the rolling window\n",
    "    roll_window = window\n",
    "    # Set the number of standard deviation\n",
    "    std_dev = 2\n",
    "    # Create a rolling window for High and Low\n",
    "    df['high_roll_max'] = df['High'].rolling(window=roll_window).max()\n",
    "    df['low_roll_min'] = df['Low'].rolling(window=roll_window).min()\n",
    "    # Calculate the mean and standard deviation for High and Low\n",
    "    mean_high = df['High'].rolling(window=roll_window).mean()\n",
    "    std_high = df['High'].rolling(window=roll_window).std()\n",
    "    mean_low = df['Low'].rolling(window=roll_window).mean()\n",
    "    std_low = df['Low'].rolling(window=roll_window).std()\n",
    "    # Create a new column for support and resistance\n",
    "    df['support'] = mean_low - std_dev * std_low\n",
    "    df['resistance'] = mean_high + std_dev * std_high\n",
    "    return df\n",
    "def detect_triangle_pattern(df, window=3):\n",
    "    # Define the rolling window\n",
    "    roll_window = window\n",
    "    # Create a rolling window for High and Low\n",
    "    df['high_roll_max'] = df['High'].rolling(window=roll_window).max()\n",
    "    df['low_roll_min'] = df['Low'].rolling(window=roll_window).min()\n",
    "    # Create a boolean mask for ascending triangle pattern\n",
    "    mask_asc = (df['high_roll_max'] >= df['High'].shift(1)) & (df['low_roll_min'] <= df['Low'].shift(1)) & (df['Close'] > df['Close'].shift(1))\n",
    "    # Create a boolean mask for descending triangle pattern\n",
    "    mask_desc = (df['high_roll_max'] <= df['High'].shift(1)) & (df['low_roll_min'] >= df['Low'].shift(1)) & (df['Close'] < df['Close'].shift(1))\n",
    "    # Create a new column for triangle pattern and populate it using the boolean masks\n",
    "    df['triangle_pattern'] = np.nan\n",
    "    df.loc[mask_asc, 'triangle_pattern'] = 1\n",
    "    df.loc[mask_desc, 'triangle_pattern'] = 2\n",
    "    return df\n",
    "\n",
    "def detect_wedge(df, window=3):\n",
    "    # Define the rolling window\n",
    "    roll_window = window\n",
    "    # Create a rolling window for High and Low\n",
    "    df['high_roll_max'] = df['High'].rolling(window=roll_window).max()\n",
    "    df['low_roll_min'] = df['Low'].rolling(window=roll_window).min()\n",
    "    df['trend_high'] = df['High'].rolling(window=roll_window).apply(lambda x: 1 if (x[-1]-x[0])>0 else -1 if (x[-1]-x[0])<0 else 0)\n",
    "    df['trend_low'] = df['Low'].rolling(window=roll_window).apply(lambda x: 1 if (x[-1]-x[0])>0 else -1 if (x[-1]-x[0])<0 else 0)\n",
    "    # Create a boolean mask for Wedge Up pattern\n",
    "    mask_wedge_up = (df['high_roll_max'] >= df['High'].shift(1)) & (df['low_roll_min'] <= df['Low'].shift(1)) & (df['trend_high'] == 1) & (df['trend_low'] == 1)\n",
    "    # Create a boolean mask for Wedge Down pattern\n",
    "        # Create a boolean mask for Wedge Down pattern\n",
    "    mask_wedge_down = (df['high_roll_max'] <= df['High'].shift(1)) & (df['low_roll_min'] >= df['Low'].shift(1)) & (df['trend_high'] == -1) & (df['trend_low'] == -1)\n",
    "    # Create a new column for Wedge Up and Wedge Down pattern and populate it using the boolean masks\n",
    "    df['wedge_pattern'] = np.nan\n",
    "    df.loc[mask_wedge_up, 'wedge_pattern'] = 1\n",
    "    df.loc[mask_wedge_down, 'wedge_pattern'] = 2\n",
    "    return df\n",
    "def detect_channel(df, window=3):\n",
    "    # Define the rolling window\n",
    "    roll_window = window\n",
    "    # Define a factor to check for the range of channel\n",
    "    channel_range = 0.1\n",
    "    # Create a rolling window for High and Low\n",
    "    df['high_roll_max'] = df['High'].rolling(window=roll_window).max()\n",
    "    df['low_roll_min'] = df['Low'].rolling(window=roll_window).min()\n",
    "    df['trend_high'] = df['High'].rolling(window=roll_window).apply(lambda x: 1 if (x[-1]-x[0])>0 else -1 if (x[-1]-x[0])<0 else 0)\n",
    "    df['trend_low'] = df['Low'].rolling(window=roll_window).apply(lambda x: 1 if (x[-1]-x[0])>0 else -1 if (x[-1]-x[0])<0 else 0)\n",
    "    # Create a boolean mask for Channel Up pattern\n",
    "    mask_channel_up = (df['high_roll_max'] >= df['High'].shift(1)) & (df['low_roll_min'] <= df['Low'].shift(1)) & (df['high_roll_max'] - df['low_roll_min'] <= channel_range * (df['high_roll_max'] + df['low_roll_min'])/2) & (df['trend_high'] == 1) & (df['trend_low'] == 1)\n",
    "    # Create a boolean mask for Channel Down pattern\n",
    "    mask_channel_down = (df['high_roll_max'] <= df['High'].shift(1)) & (df['low_roll_min'] >= df['Low'].shift(1)) & (df['high_roll_max'] - df['low_roll_min'] <= channel_range * (df['high_roll_max'] + df['low_roll_min'])/2) & (df['trend_high'] == -1) & (df['trend_low'] == -1)\n",
    "    # Create a new column for Channel Up and Channel Down pattern and populate it using the boolean masks\n",
    "    df['channel_pattern'] = np.nan\n",
    "    df.loc[mask_channel_up, 'channel_pattern'] = 1\n",
    "    df.loc[mask_channel_down, 'channel_pattern'] = 2\n",
    "    return df\n",
    "\n",
    "def detect_double_top_bottom(df, window=3, threshold=0.05):\n",
    "    # Define the rolling window\n",
    "    roll_window = window\n",
    "    # Define a threshold to check for the range of pattern\n",
    "    range_threshold = threshold\n",
    "\n",
    "    # Create a rolling window for High and Low\n",
    "    df['high_roll_max'] = df['High'].rolling(window=roll_window).max()\n",
    "    df['low_roll_min'] = df['Low'].rolling(window=roll_window).min()\n",
    "\n",
    "    # Create a boolean mask for Double Top pattern\n",
    "    mask_double_top = (df['high_roll_max'] >= df['High'].shift(1)) & (df['high_roll_max'] >= df['High'].shift(-1)) & (df['High'] < df['High'].shift(1)) & (df['High'] < df['High'].shift(-1)) & ((df['High'].shift(1) - df['Low'].shift(1)) <= range_threshold * (df['High'].shift(1) + df['Low'].shift(1))/2) & ((df['High'].shift(-1) - df['Low'].shift(-1)) <= range_threshold * (df['High'].shift(-1) + df['Low'].shift(-1))/2)\n",
    "    # Create a boolean mask for Double Bottom pattern\n",
    "    mask_double_bottom = (df['low_roll_min'] <= df['Low'].shift(1)) & (df['low_roll_min'] <= df['Low'].shift(-1)) & (df['Low'] > df['Low'].shift(1)) & (df['Low'] > df['Low'].shift(-1)) & ((df['High'].shift(1) - df['Low'].shift(1)) <= range_threshold * (df['High'].shift(1) + df['Low'].shift(1))/2) & ((df['High'].shift(-1) - df['Low'].shift(-1)) <= range_threshold * (df['High'].shift(-1) + df['Low'].shift(-1))/2)\n",
    "\n",
    "    # Create a new column for Double Top and Double Bottom pattern and populate it using the boolean masks\n",
    "    df['double_pattern'] = np.nan\n",
    "    df.loc[mask_double_top, 'double_pattern'] = 1\n",
    "    df.loc[mask_double_bottom, 'double_pattern'] = 2\n",
    "\n",
    "    return df\n",
    "\n",
    "def detect_trendline(df, window=2):\n",
    "    # Define the rolling window\n",
    "    roll_window = window\n",
    "    # Create new columns for the linear regression slope and y-intercept\n",
    "    df['slope'] = np.nan\n",
    "    df['intercept'] = np.nan\n",
    "\n",
    "    for i in range(window, len(df)):\n",
    "        x = np.array(range(i-window, i))\n",
    "        y = df['Close'][i-window:i]\n",
    "        A = np.vstack([x, np.ones(len(x))]).T\n",
    "        m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "        df.at[df.index[i], 'slope'] = m\n",
    "        df.at[df.index[i], 'intercept'] = c\n",
    "\n",
    "    # Create a boolean mask for trendline support\n",
    "    mask_support = df['slope'] > 0\n",
    "\n",
    "    # Create a boolean mask for trendline resistance\n",
    "    mask_resistance = df['slope'] < 0\n",
    "\n",
    "    # Create new columns for trendline support and resistance\n",
    "    df['support'] = np.nan\n",
    "    df['resistance'] = np.nan\n",
    "\n",
    "    # Populate the new columns using the boolean masks\n",
    "    df.loc[mask_support, 'support'] = df['Close'] * df['slope'] + df['intercept']\n",
    "    df.loc[mask_resistance, 'resistance'] = df['Close'] * df['slope'] + df['intercept']\n",
    "\n",
    "    return df\n",
    "\n",
    "def find_pivots(df):\n",
    "    # Calculate differences between consecutive highs and lows\n",
    "    high_diffs = df['High'].diff()\n",
    "    low_diffs = df['Low'].diff()\n",
    "\n",
    "    # Find higher high\n",
    "    higher_high_mask = (high_diffs > 0) & (high_diffs.shift(-1) < 0)\n",
    "    \n",
    "    # Find lower low\n",
    "    lower_low_mask = (low_diffs < 0) & (low_diffs.shift(-1) > 0)\n",
    "\n",
    "    # Find lower high\n",
    "    lower_high_mask = (high_diffs < 0) & (high_diffs.shift(-1) > 0)\n",
    "\n",
    "    # Find higher low\n",
    "    higher_low_mask = (low_diffs > 0) & (low_diffs.shift(-1) < 0)\n",
    "\n",
    "    # Create signals column\n",
    "    df['signal'] = ''\n",
    "    df.loc[higher_high_mask, 'signal'] = 1\n",
    "    df.loc[lower_low_mask, 'signal'] = 2\n",
    "    df.loc[lower_high_mask, 'signal'] = 3\n",
    "    df.loc[higher_low_mask, 'signal'] = 4\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144d2904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features added and saved for HDFC_Bank_Limited.\n",
      "Features added and saved for Hindustan_Unilever_Limited.\n",
      "Features added and saved for ITC_Limited.\n",
      "Features added and saved for Kotak_Mahindra_Bank_Limited.\n",
      "Features added and saved for Larsen_&_Toubro_Limited.\n",
      "Features added and saved for Oil_and_Natural_Gas_Corporation_Limited.\n",
      "Features added and saved for Reliance_Industries_Limited.\n",
      "Features added and saved for State_Bank_of_India.\n",
      "Features added and saved for Tata_Consultancy_Services_Limited.\n",
      "Features added and saved for Tata_Motors_Limited.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Directory paths\n",
    "datasets_directory = 'datasets'\n",
    "features_directory = 'features'\n",
    "\n",
    "# Create the features directory if it doesn't exist\n",
    "os.makedirs(features_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over each dataset file in the datasets folder\n",
    "for file_name in os.listdir(datasets_directory):\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Read the dataset\n",
    "        file_path = os.path.join(datasets_directory, file_name)\n",
    "        stock_data = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "        \n",
    "        # Apply feature engineering functions\n",
    "        stock_data = calculate_additional_features(stock_data)\n",
    "        stock_data = calculate_time_features(stock_data)\n",
    "        stock_data = detect_head_shoulder(stock_data)\n",
    "        stock_data = detect_multiple_tops_bottoms(stock_data)\n",
    "        stock_data = detect_triangle_pattern(stock_data)\n",
    "        stock_data = detect_wedge(stock_data)\n",
    "        stock_data = detect_channel(stock_data)\n",
    "        stock_data = detect_double_top_bottom(stock_data)\n",
    "        stock_data = detect_trendline(stock_data)\n",
    "        stock_data = find_pivots(stock_data)\n",
    "        # Get the stock name from the file name\n",
    "        stock_name = file_name.replace('.csv', '')  # Remove the file extension\n",
    "        \n",
    "        # Save the modified dataset to the features folder\n",
    "        features_file_name = f\"{stock_name}_features.csv\"\n",
    "        features_file_path = os.path.join(features_directory, features_file_name)\n",
    "        stock_data.to_csv(features_file_path)\n",
    "        \n",
    "        print(f\"Features added and saved for {stock_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db435146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7fc6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
